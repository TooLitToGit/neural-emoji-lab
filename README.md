# Neural Emoji Lab

> **Baked by Python. Served by JavaScript.**

An educational experiment that uses Python to pre-calculate the "Latent Space" of emojis, allowing your browser to splice their **Shape**, **Texture**, and **Color** in real-time.

## ğŸŒ Try It Live

**ğŸ‘‰ [Launch Neural Emoji Lab](https://toolittogit.github.io/neural-emoji-lab/) ğŸ‘ˆ**

### What Does It Do?

Neural Emoji Lab lets you **remix emojis by blending their features independently**. Select two parent emojis and use three sliders to control:

- **ğŸ­ Silhouette** - The shape and boundary (Cookie cutter)
- **âœ¨ Texture** - Internal details and lighting (Relief map)
- **ğŸ¨ Color** - RGB color palette (Infinite bleed)

Want the body of a ğŸ‘» ghost but the texture and color of ğŸ”¥ fire? Or perhaps a ğŸ’ diamond shape with the ghostly colors of ğŸ‘»? You can create that! Each slider independently blends between your two parent emojis. The app demonstrates **disentangled representation learning** - a core concept in modern AI systems like Stable Diffusion and VAEs.

Save your creations, hit random for inspiration, and explore the mathematical magic of latent spaces in your browser.

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Train the Model

Run the Python training script to generate the neural network data:

```bash
python train.py
```

This will:

- Download the Noto Color Emoji font
- Process ~200+ popular emojis
- Train three Ridge Regression models (Silhouette, Texture, Color)
- Export training data to `public/data/` directory

### 3. Serve the Web App

Use Node's http-server (or any static file server):

```bash
npx http-server public -p 3000
```

Or with Python:

```bash
python -m http.server 3000 --directory public
```

### 4. Open in Browser

Navigate to: http://localhost:3000

## ğŸ“ Architecture

This project uses a **"Compute-Once, Run-Anywhere"** architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python         â”‚  Train three Ridge Regression models
â”‚  train.py       â”‚  â€¢ Silhouette (alpha channel)
â”‚                 â”‚  â€¢ Texture (high-pass filter)
â”‚                 â”‚  â€¢ Color (infinite bleed)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Exports JSON
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  public/data/   â”‚  Pre-computed training data
â”‚  â€¢ meta.json    â”‚  â€¢ Emoji metadata & previews
â”‚  â€¢ latents.json â”‚  â€¢ Random latent codes
â”‚  â€¢ weights_*.json  Learned weight matrices
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Loads in browser
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JavaScript     â”‚  Real-time inference
â”‚  app.js         â”‚  â€¢ Matrix multiplication
â”‚                 â”‚  â€¢ Feature interpolation
â”‚                 â”‚  â€¢ Canvas rendering
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§  How It Works

### Three Independent Feature Channels

1. **Silhouette** - The shape/boundary (from alpha channel)
2. **Texture** - Internal details/lighting (high-pass filtered)
3. **Color** - RGB values with infinite bleed effect

### Training

Uses Ridge Regression (closed-form solution) instead of gradient descent:

```
W = (X^T X + Î»I)^(-1) X^T Y
```

Where:

- `X` = Random latent codes (N Ã— 512)
- `Y` = Extracted features (N Ã— 4096)
- `Î»` = Regularization parameter (5.0)

### Inference

In the browser, we:

1. Interpolate between two latent vectors
2. Multiply by weight matrices (`z @ W`)
3. Composite the three channels into final image

## ğŸ¨ Usage

1. Select two parent emojis (A and B)
2. Adjust three sliders:
   - **Silhouette**: Morph the shape between A and B
   - **Texture**: Blend internal details
   - **Color**: Mix color palettes
3. Click **Save** to download your creation
4. Click **Random** to discover new combinations

## ğŸ“ Project Structure

```
neural-emoji-lab/
â”œâ”€â”€ train.py              # Python training script
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ index.html       # Web interface
â”‚   â”œâ”€â”€ app.js           # Browser inference engine
â”‚   â””â”€â”€ data/            # Generated training data (created by train.py)
â”‚       â”œâ”€â”€ meta.json
â”‚       â”œâ”€â”€ latents.json
â”‚       â”œâ”€â”€ weights_sil.json
â”‚       â”œâ”€â”€ weights_tex.json
â”‚       â””â”€â”€ weights_col.json
â””â”€â”€ README.md
```

## ğŸ”¬ Technical Details

- **Image Size**: 64Ã—64 pixels
- **Latent Dimension**: 512
- **Regularization**: Î» = 5.0
- **Precision**: 4 decimal places
- **Dataset**: ~200+ popular emojis from Unicode

## ğŸ’¡ Key Concepts

### Disentangled Representation

By training three separate models, we force the network to learn independent features. This allows surgical controlâ€”you can take the shape of a ğŸ‘» ghost, the texture of a ğŸ’ diamond, and the color of ğŸ”¥ fire.

### Ridge Regression

Instead of backpropagation, we use a closed-form solution that's instant and deterministic. Perfect for educational demonstrations.

### Infinite Color Bleed

We pre-process training images to "smear" colors into empty space, ensuring color information exists everywhere. This prevents black artifacts when morphing shapes.

## ğŸ› ï¸ Development

### Modify Emoji List

Edit the `POPULAR_EMOJIS` string in [train.py](train.py) to include your own emoji selection.

### Adjust Parameters

In [train.py](train.py):

- `IMG_SIZE`: Resolution (default: 64)
- `LATENT_DIM`: Latent space dimensions (default: 512)
- `LAMBDA`: Ridge regression regularization (default: 5.0)
- `DECIMALS`: JSON precision (default: 4)

### Re-train

After changes, re-run:

```bash
python train.py
```

## ğŸ“ License

MIT

## ğŸ™ Credits

- Font: [Noto Color Emoji](https://github.com/googlefonts/noto-emoji) by Google
- Inspired by modern generative AI concepts (VAEs, Stable Diffusion)
